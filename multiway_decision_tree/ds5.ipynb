{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefa868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dea7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import string\n",
    "from string import ascii_lowercase\n",
    "import multiway_decision_tree as mdt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8acc2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data( data ):\n",
    "    X_raw = data[:,:-1]\n",
    "    y_raw = data[:,-1]\n",
    "    \n",
    "    X = np.cumprod( np.flip( 2 * X_raw - 1 , axis = 1 ), axis = 1 )\n",
    "    y = np.where( y_raw > 0, 1, -1 )\n",
    "    \n",
    "    return ( X, y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8573fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt( \"APUF_CRP.txt\" )\n",
    "\n",
    "data_trn, data_tst = train_test_split( data, train_size = 10000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffda907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9940111111111111"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( X, y ) = preprocess_data( data_trn )\n",
    "( X_t, y_t ) = preprocess_data( data_tst )\n",
    "\n",
    "clf = LinearSVC( loss = \"hinge\" )\n",
    "clf.fit( X, y )\n",
    "\n",
    "w = clf.coef_.reshape( (32,) )\n",
    "b = clf.intercept_\n",
    "temp = X_t.dot(w) + b\n",
    "y_t_pred = np.where( temp > 0, 1, -1 )\n",
    "\n",
    "np.average( y_t == y_t_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb61653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PUF_split_actor:\n",
    "    def __init__( self, attr, pop_label ):\n",
    "        self.attr = attr\n",
    "        self.pop_label = pop_label\n",
    "        \n",
    "    def get_attr( self ):\n",
    "        return self.attr\n",
    "    \n",
    "    def split( self, tst_pts, ancestors ):\n",
    "        split_dict = {}\n",
    "        \n",
    "#         print( len( tst_pts ), end = '' )\n",
    "        \n",
    "        for val in np.unique( tst_pts[ :, self.attr ] ):\n",
    "            idx = np.where( tst_pts[ :, self.attr ] == val )[0].tolist()\n",
    "            split_dict[ val ] = ( idx, tst_pts[ idx, : ]  )\n",
    "#             print( \"[\",idx,\"]\", end = '' )\n",
    "        \n",
    "#         print()\n",
    "        return split_dict\n",
    "        \n",
    "    def default_predict( self, tst_pts, ancestors ):\n",
    "        preds = []\n",
    "        \n",
    "        for x in tst_pts:\n",
    "            preds.append( self.pop_label )\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "class PUF_leaf_actor:\n",
    "    def __init__( self, pop_label ):\n",
    "        self.pop_label = pop_label\n",
    "        \n",
    "    def predict( self, tst_pts, ancestors ):\n",
    "        preds = []\n",
    "        \n",
    "        for x in tst_pts:\n",
    "            preds.append( self.pop_label )\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "    def default_predict( self, tst_pt, ancestors ):\n",
    "        return self.predict( tst_pts, ancestors )\n",
    "\n",
    "def get_PUF_size( trn_pts ):\n",
    "    return len( trn_pts[ 1 ] )\n",
    "\n",
    "def is_PUF_pure_enough( trn_pts ):\n",
    "    labels = trn_pts[ 1 ]\n",
    "    # Pure enough for us if the labels are more than 99% pure\n",
    "    # Since labels are +1/-1 valued this will happen exactly\n",
    "    # when the average label has a magnitude greater than\n",
    "    # 0.99 - (1 - 0.99)) = 0.98\n",
    "    # Similarly, to get 95% purity, we should ask for the\n",
    "    # magtinude to be greater than 0.95 - (1 - 0.95) = 0.90\n",
    "    if np.abs( np.mean( labels ) ) > 0.98:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_PUF_leaf_actor( trn_pts, ancestors ):\n",
    "    labels = trn_pts[ 1 ]\n",
    "    ( classes, counts ) = np.unique( labels, return_counts = True )    \n",
    "    return PUF_leaf_actor( pop_label = classes[ np.argmax( counts ) ] )\n",
    "\n",
    "# See the following StackOverflow conversation on some alternate ways to compute entropy\n",
    "# https://stackoverflow.com/questions/15450192/fastest-way-to-compute-entropy-in-python\n",
    "def get_PUF_entropy( labels ):    \n",
    "    \n",
    "    _, counts = np.unique( labels, return_counts = True )\n",
    "    \n",
    "    # Why include elements that do not appear at all?\n",
    "    assert np.min( counts ) > 0, \"Elements with zero or negative counts detected\"\n",
    "    \n",
    "    num_elements = counts.sum()\n",
    "    \n",
    "    # A singular or empty set has zero entropy\n",
    "    if num_elements <= 1:\n",
    "#         print( f\"warning: { num_elements } elements in total\" )\n",
    "        return 0\n",
    "    \n",
    "    proportions = counts / num_elements\n",
    "    \n",
    "    return -np.sum( proportions * np.log2( proportions ) )\n",
    "\n",
    "def try_PUF_attr( a, X, y ):\n",
    "    n = len( y )\n",
    "    assert n == X.shape[ 0 ], \"Mismatch in number of features and number of labels\"\n",
    "    \n",
    "    split_dict = {}\n",
    "    entropy = 0\n",
    "        \n",
    "    for val in np.unique( X[ :, a ] ):\n",
    "        # Find out who all would go to this child\n",
    "        idx = np.where( X[ :, a ] == val )[0].tolist()\n",
    "        split_dict[ val ] = ( X[ idx, : ], y[ idx ] )\n",
    "        # Calculate the entropy of the child\n",
    "        entropy += len(idx) / n * get_PUF_entropy( y[ idx ] )\n",
    "    \n",
    "    return ( entropy, split_dict )\n",
    "\n",
    "def get_PUF_split_actor( trn_pts, ancestors ):\n",
    "    ( X, y ) = trn_pts\n",
    "    ( n, d ) = X.shape\n",
    "    \n",
    "    # Exclude the attribute used by my parent to split my siblings and me\n",
    "    if len( ancestors ) < 1:\n",
    "        parent_attr = -1\n",
    "    else:\n",
    "        parent_attr = ancestors[-1][0]\n",
    "    \n",
    "    best_entropy = np.inf\n",
    "    best_attr = -1\n",
    "    best_split_dict = None\n",
    "    \n",
    "    for a in [ attr for attr in np.arange( d ) if not attr == parent_attr ]:\n",
    "        ( entropy, split_dict ) = try_PUF_attr( a, X, y )\n",
    "#         print( f\"{a}({entropy})\", end = \", \" )\n",
    "        if entropy < best_entropy:\n",
    "            best_entropy = entropy\n",
    "            best_attr = a\n",
    "            best_split_dict = split_dict\n",
    "    \n",
    "#     print()\n",
    "    \n",
    "#     print( f\"\\n\\n\\n{best_attr}({best_entropy})\" )\n",
    "    ( classes, counts ) = np.unique( y, return_counts = True )\n",
    "#     print( f\"\\n\\n\\n{ counts } --> \", end = '' )\n",
    "    for ( XX, yy ) in best_split_dict.values():\n",
    "        ( _, cc ) = np.unique( yy, return_counts = True )\n",
    "#         print( f\"{ cc }, \", end = '' )\n",
    "    \n",
    "    pop_label = classes[ np.argmax( counts ) ]\n",
    "    return ( PUF_split_actor( best_attr, pop_label ), best_split_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a5834e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_depth = 15\n",
    "\n",
    "dt_PUF = mdt.Tree( min_leaf_size = 1, max_depth = max_depth )\n",
    "dt_PUF.train( ( X, y ), get_PUF_split_actor, get_PUF_leaf_actor, is_PUF_pure_enough, get_PUF_size )\n",
    "\n",
    "with open( \"dt_PUF.mdl\", \"wb\" ) as f:\n",
    "    pickle.dump( dt_PUF, f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7023c346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training accuracy\n",
    "y_pred = np.array( dt_PUF.predict( X ) )\n",
    "np.average( y == y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c199c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8197222222222222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy\n",
    "y_t_pred = np.array( dt_PUF.predict( X_t ) )\n",
    "np.average( y_t == y_t_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7cb03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "email": "purushot@cse.iitk.ac.in",
   "institution": "IIT Kanpur",
   "name": "Puru"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
